{
 "metadata": {
  "name": "",
  "signature": "sha256:41283bee9755622c05a4edcf1c77de09f682549cafa695b4de7137ca3af75b03"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Downloading Geotagged Tweets\n",
      "\n",
      "Sam Maurer // DCRP PhD Student // maurer@berkeley.edu // Nov. 6, 2014 // CP 255 demo\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from TwitterAPI import TwitterAPI\n",
      "import json\n",
      "import time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### First we'll open a connection to the Twitter API\n",
      "\n",
      "Replace these API key codes with your own if you have them!  \n",
      "Twitter imposes rate limits, so if the whole class uses our demo keys, some of the requests will fail."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "consumer_key = 'Bas6XAA8fuptlhLi1NxQGDIpW'\n",
      "consumer_secret = 'JsRyIMfKA5XpcrXgPYndI2UPWP4u9x3VIcnnt5xyuBDhVHPbSx'\n",
      "access_token_key = '1914664969-RpwXMIMXMHGXqxPYhsWdV66FoXddSHj5qvAo0xP'\n",
      "access_token_secret = 'COi3A2SBCk0dnrhbENdRiG0antsL85tLWutKmQx6jlF66'\n",
      "\n",
      "api = TwitterAPI(consumer_key, consumer_secret, access_token_key, access_token_secret)\n",
      "print 'success'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Here's a simple request"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Most recent tweet from @Pete_sw's timeline\n",
      "\n",
      "endpoint = 'search/tweets'\n",
      "params = {\n",
      "    'q': '#NYC', \n",
      "    'count': 10\n",
      "}\n",
      "r = api.request(endpoint, params)\n",
      "\n",
      "for tweet in r.get_iterator():\n",
      "    print tweet['text'] + tweet['lang']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Contents of some additional fields...\n",
      "# Here are the definitions: https://dev.twitter.com/overview/api/tweets\n",
      "\n",
      "for tweet in r.get_iterator():\n",
      "    print \"Tweet      // \", tweet['text']\n",
      "    print \"Timestamp  // \", tweet['created_at']\n",
      "    print \"Retweets   // \", tweet['retweet_count']\n",
      "    print \"Favorites  // \", tweet['favorite_count']\n",
      "    print \"Geotag     // \", tweet['coordinates']\n",
      "    print \"Language   // \", tweet['lang']\n",
      "    print \"User       // \", tweet['user']['screen_name']\n",
      "    print \"Followers  // \", tweet['user']['followers_count']\n",
      "    print \"Profile    // \", tweet['user']['description']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Other API endpoints allow different types of searches"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Search for public tweets about #muni\n",
      "\n",
      "endpoint = 'search/tweets'\n",
      "params = {\n",
      "    'q': '#NYC', \n",
      "    'count': 10\n",
      "}\n",
      "r = api.request(endpoint, params)\n",
      "\n",
      "for tweet in r.get_iterator():\n",
      "    print tweet['text']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Search for public tweets in Hindi\n",
      "\n",
      "endpoint = 'search/tweets'\n",
      "params = {\n",
      "    'q': '*', \n",
      "    'lang': 'hi', \n",
      "    'count': 5\n",
      "} \n",
      "r = api.request(endpoint, params)\n",
      "\n",
      "for tweet in r.get_iterator():\n",
      "    print tweet['text']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Search for public tweets geotagged near the UC Berkeley campus\n",
      "\n",
      "endpoint = 'search/tweets'\n",
      "params = {\n",
      "    'q': '#based', \n",
      "    'count': 10\n",
      "} \n",
      "r = api.request(endpoint, params)\n",
      "\n",
      "for tweet in r.get_iterator():\n",
      "    print tweet['text']\n",
      "    print '\\n'\n",
      "    print tweet\n",
      "    print '\\n'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Exercise: \n",
      "# 1 - Try some different search queries!\n",
      "# 2 - Try adding 'result_type':'popular' or 'result_type':'recent'\n",
      "# 3 - Display some more fields in addition to the tweet text\n",
      "\n",
      "# Here's the search documentation: https://dev.twitter.com/rest/reference/get/search/tweets\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### You can even stream live tweets continuously "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Twitter strictly limits connections to the streaming APIs  \n",
      "# Please try this part only if you've entered your own API keys, or after class!\n",
      "\n",
      "if consumer_key == 'MAZ0H5ypNlPWKG4R2MUqXA':\n",
      "    print 'Please try this part after class or using your own API keys!'\n",
      "\n",
      "else:\n",
      "    endpoint = 'statuses/filter'\n",
      "    #set for just new york\n",
      "    params = {'locations':'-74,40,-73,41'}\n",
      "    r = api.request(endpoint, params)\n",
      "    \n",
      "    tweets = r.get_iterator()\n",
      "    for i in range(500):\n",
      "        t = tweets.next()\n",
      "        #Just printing those with a certain hashtag\n",
      "        if 'NYC' in t['entities']['user_mentions']:\n",
      "            print t['text'], '\\n'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "endpoint = 'statuses/filter'\n",
      "params = {'track': '#based'}\n",
      "r = api.request(endpoint, params)\n",
      "\n",
      "tweets = r.get_iterator()\n",
      "for i in range(100):\n",
      "    t = tweets.next()\n",
      "    print t['text'] + '\\n'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Here's how to save tweets to a text file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# First, run a query\n",
      "\n",
      "endpoint = 'search/tweets'\n",
      "params = {\n",
      "    'q': '#love', \n",
      "    'count': 9990000\n",
      "}\n",
      "r = api.request(endpoint, params)\n",
      "\n",
      "print 'success'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Simple version: save one tweet to each line of a file\n",
      "counter = 0\n",
      "with open('geojson/nyc-tweets.json', 'wb') as f:\n",
      "    for tweet in r.get_iterator():\n",
      "         f.write(json.dumps(tweet) + '\\n')\n",
      "         #print tweet['text'], '\\n'\n",
      "         counter += 1\n",
      "print counter\n",
      "print 'tweets saved to file'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# But to visualize it on a map, we have to add more structure to the data\n",
      "\n",
      "#Set up the query\n",
      "TRACK_TERM = 'pizza'\n",
      "params = {'geocode': '-74,40,-73,41', 'track':TRACK_TERM}\n",
      "r = api.request('statuses/filter', params)\n",
      "\n",
      "geo_data = {\n",
      "    'type': 'FeatureCollection', \n",
      "    'features': []\n",
      "}\n",
      "\n",
      "with open('geojson/nycpizza-tweets.json', 'wb') as g:\n",
      "    with open('geojson/nycpizza-tweets.geojson', 'wb') as f:\n",
      "        for tweet in r.get_iterator():\n",
      "            g.write(json.dumps(tweet) + '\\n')\n",
      "\n",
      "            if tweet['coordinates']:   # (check for coord data)\n",
      "                #Print the tweet\n",
      "                print tweet['text'] + '\\n' \n",
      "                # Each tweet is a GeoJSON \"feature\"\n",
      "                feature = {\n",
      "                    'type': 'Feature', \n",
      "                    'geometry': tweet['coordinates'], \n",
      "\n",
      "                    # A feature's \"properties\" become attribute columns in GIS\n",
      "                    'properties': {\n",
      "                        'tweet': tweet['text'], \n",
      "                        'timestamp': tweet['created_at']\n",
      "                    }\n",
      "                }     \n",
      "                # Add the feature into the GeoJSON wrapper\n",
      "                geo_data['features'].append(feature)\n",
      "\n",
      "                json.dump(geo_data, f, indent=2)\n",
      "    \n",
      "          \n",
      "print len(geo_data['features']), 'geotagged tweets saved to file'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Exercise:\n",
      "# 1 - Write at least TWO different queries and save the results to GeoJSON files\n",
      "#     (geographic locations should be similar, so we can map them jointly)\n",
      "# 2 - Try opening the files in QGIS or on http://geojson.io\n",
      "\n",
      "# Advanced:\n",
      "# 3 - If you have your own API key, try streaming some tweets\n",
      "#     The format for the bounding coordinates is 'lng_min,lat_min,lng_max,lat_max'\n",
      "#     (handy site for looking up coords: http://latlong.net)\n",
      "# 4 - Try modifying my code to save the streamed tweets as a GeoJSON file\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TRACK_TERM = '#bagel'\n",
      "params = {'locations':'-74.2589, 40.4766, -73.7004, 40.9176', \n",
      "          'track':TRACK_TERM}\n",
      "r = api.request('statuses/filter', params)\n",
      "\n",
      "for tweet in r.get_iterator():\n",
      "    print tweet['text']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#track wasn't working for some reason\n",
      "params = {'locations': '-180,-90,180,90'}\n",
      "r = api.request('statuses/filter', params)\n",
      "\n",
      "\n",
      "geo_data = {\n",
      "    'type': 'FeatureCollection', \n",
      "    'features': []\n",
      "}\n",
      "\n",
      "geo_data2 = {\n",
      "    'type': 'FeatureCollection', \n",
      "    'features': []\n",
      "}\n",
      "\n",
      "for tweet in r.get_iterator():\n",
      "    if tweet['coordinates']:   # (check for coord data)\n",
      "        # Each tweet is a GeoJSON \"feature\"\n",
      "        #But for some reason I'm returning a few points outside of my bounding box\n",
      "        #So I'm just going to get rid of those\n",
      "        \n",
      "        #And for some goddamn reason the track for the term isn't working\n",
      "        \n",
      "        #Pizza    \n",
      "        #if float(tweet['coordinates']['coordinates'][0]) > -74.2589 and float(tweet['coordinates']['coordinates'][0]) < -73.7004 and float(tweet['coordinates']['coordinates'][1]) > 40.4766 and float(tweet['coordinates']['coordinates'][1]) < 40.9176 and ('pizza' in tweet['text']):\n",
      "        if 'pizza' in tweet['text']: \n",
      "            print tweet['text']\n",
      "            feature = {\n",
      "                'type': 'Feature', \n",
      "                'geometry': tweet['coordinates'], \n",
      "\n",
      "                # A feature's \"properties\" become attribute columns in GIS\n",
      "                'properties': {\n",
      "                    'tweet': tweet['text'], \n",
      "                    'timestamp': tweet['created_at']\n",
      "                }\n",
      "            }\n",
      "\n",
      "            # Add the feature into the GeoJSON wrapper\n",
      "            geo_data['features'].append(feature)\n",
      "        \n",
      "        #Hamburger\n",
      "        #if float(tweet['coordinates']['coordinates'][0]) > -74.2589 and float(tweet['coordinates']['coordinates'][0]) < -73.7004 and float(tweet['coordinates']['coordinates'][1]) > 40.4766 and float(tweet['coordinates']['coordinates'][1]) < 40.9176 and ('burger' in tweet['text']):\n",
      "        if 'burger' in tweet['text']:\n",
      "            print tweet['text']\n",
      "            feature2 = {\n",
      "                'type': 'Feature', \n",
      "                'geometry': tweet['coordinates'], \n",
      "\n",
      "                # A feature's \"properties\" become attribute columns in GIS\n",
      "                'properties': {\n",
      "                    'tweet': tweet['text'], \n",
      "                    'timestamp': tweet['created_at']\n",
      "                }\n",
      "            }\n",
      "\n",
      "            # Add the feature into the GeoJSON wrapper\n",
      "            geo_data2['features'].append(feature2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Save tweets to file\n",
      "with open('geojson/atsymbols.geojson', 'wb') as f:\n",
      "    json.dump(geo_data, f, indent=2)\n",
      "            \n",
      "print len(geo_data['features']), 'geotagged tweets saved to file'\n",
      "\n",
      "with open('geojson/hashtags.geojson', 'wb') as g:\n",
      "    json.dump(geo_data2, g, indent=2)\n",
      "            \n",
      "print len(geo_data['features']), 'geotagged tweets saved to file'\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Bagels and Pizza near NYC"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Pizza with timing\n",
      "TRACK_TERM2 = '#pizza, #pizzas'\n",
      "params2 = {'locations':'-74.2589, 40.4766, -73.7004, 40.9176', \n",
      "          'track':TRACK_TERM2}\n",
      "r2 = api.request('statuses/filter', params2)\n",
      "\n",
      "\n",
      "geo_data2 = {\n",
      "    'type': 'FeatureCollection', \n",
      "    'features': []\n",
      "}\n",
      "\n",
      "t1 = time.time()\n",
      "print \"Start time is \" + str(t1)\n",
      "\n",
      "for tweet2 in r2.get_iterator():\n",
      "    #Only running for a set number of seconds\n",
      "    if time.time() - t1 > 30:\n",
      "        break\n",
      "    if tweet2['coordinates']:   # (check for coord data)\n",
      "        # Each tweet is a GeoJSON \"feature\"\n",
      "        #But for some reason I'm returning a few points outside of my bounding box\n",
      "        #So I'm just going to get rid of those\n",
      "        if float(tweet2['coordinates']['coordinates'][0]) > -74.2589 and float(tweet2['coordinates']['coordinates'][0]) < -73.7004 and float(tweet2['coordinates']['coordinates'][1]) > 40.4766 and float(tweet2['coordinates']['coordinates'][1]) < 40.9176:\n",
      "            feature2 = {\n",
      "                'type': 'Feature', \n",
      "                'geometry': tweet2['coordinates'], \n",
      "\n",
      "                # A feature's \"properties\" become attribute columns in GIS\n",
      "                'properties': {\n",
      "                    'tweet': tweet2['text'], \n",
      "                    'timestamp': tweet2['created_at']\n",
      "                }\n",
      "            }\n",
      "\n",
      "        # Add the feature into the GeoJSON wrapper\n",
      "        geo_data2['features'].append(feature2)\n",
      "    \n",
      "with open('geojson/nycpizzatweets.geojson', 'wb') as f2:\n",
      "    json.dump(geo_data2, f2, indent=2)\n",
      "            \n",
      "print len(geo_data['features']), 'geotagged tweets saved to file'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TRACK_TERM = 'pizza'\n",
      "#'locations':'-74.2589, 40.4766, -73.7004, 40.9176'\n",
      "r = api.request('statuses/filter', {'track': TRACK_TERM})\n",
      "\n",
      "pizza_geo_data = {\n",
      "    'type': 'FeatureCollection', \n",
      "    'features': []\n",
      "}\n",
      "\n",
      "for tweet in r:\n",
      "    #print(item['text'] if 'text' in item else item)\n",
      "    if tweet['coordinates']:   # (check for coord data)\n",
      "        print tweet['text'] + '\\n' \n",
      "        # Each tweet is a GeoJSON \"feature\"\n",
      "        feature = {\n",
      "            'type': 'Feature', \n",
      "            'geometry': tweet['coordinates'], \n",
      "            \n",
      "            # A feature's \"properties\" become attribute columns in GIS\n",
      "            'properties': {\n",
      "                'tweet': tweet['text'], \n",
      "                'timestamp': tweet['created_at']\n",
      "            }\n",
      "        }\n",
      "        \n",
      "        # Add the feature into the GeoJSON wrapper\n",
      "        pizza_geo_data['features'].append(feature)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\"@PenguinTruths: When you eat a whole pizza by yourself http://t.co/bOMjIPsQka\" awhh the brown penguin so fluffy;\ud83d\ude0d\ud83d\ude0d\ud83d\ude0d\n",
        "\n",
        "I love pizza man\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "vo comer pizza \ud83c\udf74\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "@MadelaineWelch pizza cures all ailments\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "I'm at Boston's The Gourmet Pizza in Villahermosa, TAB https://t.co/taBOqtDAiy\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\u201c@antijokeapple: when you eat a whole pizza by yourself http://t.co/YsScaXrdN1\u201d so fat @_hayleyalyssa @AssassinSerafin \ud83d\ude02\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Liv left me in her room w/ it smelling of pizza&amp;its making me feel sick but  it now smells of hair spray, starting to regret sprayin it ew\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Pizza http://t.co/a3Vqha1A49\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Rach: \"I want a margarita\"\n",
        "Halle: \"Pizza? Me too\"\n",
        "Rach: \"No I want a margarita\"\n",
        "Halle: \"Pizza? Me too. We could do this all night rach\"\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Vou comer pizza e deitar\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "#nofilter #Love #Family @ Bread Factory &amp; Mariella Pizza http://t.co/JtEPnmsOnx\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "PIZZA DINNER @ Ciudad de  Mendoza , Argentina http://t.co/qK8hOONPX0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Y si me da hambre ya tengo pizza.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Acabou de publicar uma foto @ Famiglia Mancini Pizza e Pasta http://t.co/1MmrZAKbvn\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-364-f57c42bf8041>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m }\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;31m#print(item['text'] if 'text' in item else item)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'coordinates'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m# (check for coord data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/Peter_Swigert/anaconda/lib/python2.7/site-packages/TwitterAPI/TwitterAPI.pyc\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;34m\"\"\"Return a tweet status as a JSON object.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/Peter_Swigert/anaconda/lib/python2.7/site-packages/requests/models.pyc\u001b[0m in \u001b[0;36miter_lines\u001b[0;34m(self, chunk_size, decode_unicode)\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0mpending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_unicode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_unicode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpending\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/Peter_Swigert/anaconda/lib/python2.7/site-packages/requests/models.pyc\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    651\u001b[0m                 \u001b[0;31m# Special case for urllib3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 653\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    654\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/Peter_Swigert/anaconda/lib/python2.7/site-packages/requests/packages/urllib3/response.pyc\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \"\"\"\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/Peter_Swigert/anaconda/lib/python2.7/site-packages/requests/packages/urllib3/response.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp_bytes_read\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \"\"\"\n\u001b[1;32m    145\u001b[0m         \u001b[0mSimilar\u001b[0m \u001b[0mto\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mmeth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0mhttplib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPResponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbut\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtwo\u001b[0m \u001b[0madditional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 364
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('geojson/globalpizzatweets.geojson', 'wb') as f2:\n",
      "    json.dump(pizza_geo_data, f2, indent=2)\n",
      "            \n",
      "print len(pizza_geo_data['features']), 'geotagged tweets saved to file'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "14 geotagged tweets saved to file\n"
       ]
      }
     ],
     "prompt_number": 365
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}